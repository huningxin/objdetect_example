<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>OpenCV.js Haar Detection Example</title>
<link href="style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<h2>OpenCV.js Haar Detection Example</h2>
<p id="status">
</p>
<div>
<div class="control"><button id="startAndStop" disabled>Start</button></div>
</div>
<p class="err" id="errorMessage"></p>
<div>
    <table cellpadding="0" cellspacing="0" width="0" border="0">
    <tr>
        <td>
            <video id="videoInput" width=320 height=240></video>
        </td>
        <td>
            <canvas id="canvasOutput" width=320 height=240></canvas>
        </td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>
            <div class="caption">videoInput</div>
        </td>
        <td>
            <div class="caption">canvasOutput</div>
        </td>
        <td></td>
        <td></td>
    </tr>
    </table>
</div>
<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stats.js/r16/Stats.min.js" type="text/javascript"></script>
<script src="utils.js" type="text/javascript"></script>
<script id="codeSnippet" type="text/code-snippet">


// schedule the first one.
setTimeout(processVideo, 0);
</script>
<script type="text/javascript">
let utils = new Utils('errorMessage');

let streaming = false;
let videoInput = document.getElementById('videoInput');
let startAndStop = document.getElementById('startAndStop');
let canvasOutput = document.getElementById('canvasOutput');
let canvasContext = canvasOutput.getContext('2d');

startAndStop.addEventListener('click', () => {
    if (!streaming) {
        utils.clearError();
        utils.startCamera('qvga', onVideoStarted, 'videoInput');
    } else {
        utils.stopCamera();
        onVideoStopped();
    }
});

function onVideoStarted() {
    streaming = true;
    startAndStop.innerText = 'Stop';
    videoInput.width = videoInput.videoWidth;
    videoInput.height = videoInput.videoHeight;
    startProcessing();
}

function onVideoStopped() {
    streaming = false;
    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
    startAndStop.innerText = 'Start';
}

let classifier;
let stats;

function startProcessing() {
    let video = document.getElementById('videoInput');
    let mat = new cv.Mat(video.height, video.width, cv.CV_8UC1);
    var canvas = document.getElementById('canvasOutput');
    canvas.width = video.width;
    canvas.height = video.height;
    let gray = new Uint8Array(video.width * video.height);
    let ctx = canvas.getContext('2d');
    let faces = new cv.RectVector();

    const FPS = 30;
    function processVideo() {
        try {
            if (!streaming) {
                // clean and stop.
                mat.delete();
                faces.delete();
                return;
            }
            stats.begin();
            let begin = Date.now();
            // start processing.
            ctx.drawImage(video, 0, 0, video.width, video.height);
            rgbaToGray(ctx.getImageData(0, 0, video.width, video.height).data, gray);
            mat.data.set(gray);
            // detect faces.
            let minSize = {width: 0, height: 0};
            classifier.detectMultiScale(mat, faces, 1.1, 3, 0, minSize, mat.size());
            // draw faces.
            drawResults(ctx, faces, 'red', mat.size());
            stats.end();
            // schedule the next one.
            let delay = 1000/FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        } catch (err) {
            utils.printError(err);
        }
    };

    setTimeout(processVideo, 0);
}

function rgbaToGray(src, dst) {
    for (let i = 0, j = 0; i < src.length; i += 4, j += 1) {
      dst[j] = (src[i] * 77 + src[i + 1] * 150 + src[i + 2] * 29) >> 8;
    }
}

function drawResults(ctx, results, color, size) {
    for (let i = 0; i < results.size(); ++i) {
        let rect = results.get(i);
        ctx.lineWidth = 3;
        ctx.strokeStyle = color;
        ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
    }
}

function initGUI() {
    startAndStop.removeAttribute('disabled');

    stats = new Stats();
    stats.showPanel(0);
    document.body.appendChild(stats.domElement);
    stats.domElement.style.position = 'absolute';
    stats.domElement.style.right = '0px';
    stats.domElement.style.top = '0px';
}

utils.loadOpenCv(() => {
    const cascadeFileUrl = './haarcascade_frontalface_default.xml';
    utils.loadFileFromUrl(cascadeFileUrl, (xml) => {
        try {
            classifier = new cv.CascadeClassifier();
            // load pre-trained classifiers
            classifier.load(xml);
            document.getElementById('status').innerText =
                'Succeed to load haar cascade file ' + cascadeFileUrl;
            initGUI();
        } catch (err) {
            utils.printError(err);
        }
    });
});
</script>
</body>
</html>
