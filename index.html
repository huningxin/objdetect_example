<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>OpenCV.js objdetect example</title>
<link href="style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<h2>OpenCV.js objdetect example</h2>
<p>
    Click <b>Start/Stop</b> button to start or stop the camera capture.<br>
    The <b>videoInput</b> is a &lt;video&gt; element used as face detector input.
    The <b>canvasOutput</b> is a &lt;canvas&gt; element used as face detector output.<br>
</p>
<div>
<div class="control"><button id="startAndStop" disabled>Start</button></div>
</div>
<p class="err" id="errorMessage"></p>
<div>
    <table cellpadding="0" cellspacing="0" width="0" border="0">
    <tr>
        <td>
            <video id="videoInput" width=320 height=240></video>
        </td>
        <td>
            <canvas id="canvasOutput" width=320 height=240></canvas>
        </td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>
            <div class="caption">videoInput</div>
        </td>
        <td>
            <div class="caption">canvasOutput</div>
        </td>
        <td></td>
        <td></td>
    </tr>
    </table>
</div>
<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
<script src="utils.js" type="text/javascript"></script>
<script id="codeSnippet" type="text/code-snippet">


// schedule the first one.
setTimeout(processVideo, 0);
</script>
<script type="text/javascript">
let utils = new Utils('errorMessage');

let streaming = false;
let videoInput = document.getElementById('videoInput');
let startAndStop = document.getElementById('startAndStop');
let canvasOutput = document.getElementById('canvasOutput');
let canvasContext = canvasOutput.getContext('2d');

startAndStop.addEventListener('click', () => {
    if (!streaming) {
        utils.clearError();
        utils.startCamera('qvga', onVideoStarted, 'videoInput');
    } else {
        utils.stopCamera();
        onVideoStopped();
    }
});

function onVideoStarted() {
    streaming = true;
    startAndStop.innerText = 'Stop';
    videoInput.width = videoInput.videoWidth;
    videoInput.height = videoInput.videoHeight;
    startProcessing();
}

function onVideoStopped() {
    streaming = false;
    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
    startAndStop.innerText = 'Start';
}

var xml;

function startProcessing() {
    let video = document.getElementById('videoInput');
    let mat = new cv.Mat(video.height, video.width, cv.CV_8UC1);
    var canvas = document.getElementById('canvasOutput');
    canvas.width = video.width;
    canvas.height = video.height;
    let gray = new Uint8Array(video.width * video.height);
    let ctx = canvas.getContext('2d');
    let faces = new cv.RectVector();
    let classifier = new cv.CascadeClassifier();

    // load pre-trained classifiers
    classifier.load(xml);

    const FPS = 30;
    function processVideo() {
        try {
            if (!streaming) {
                // clean and stop.
                mat.delete();
                faces.delete();
                classifier.delete();
                return;
            }
            let begin = Date.now();
            // start processing.
            ctx.drawImage(video, 0, 0, video.width, video.height);
            rgbaToGray(ctx.getImageData(0, 0, video.width, video.height).data, gray);
            mat.data.set(gray);
            // detect faces.
            let minSize = {width: 0, height: 0};
            classifier.detectMultiScale(mat, faces, 1.1, 3, 0, minSize, mat.size());
            // draw faces.
            drawResults(ctx, faces, 'red', mat.size());
            // schedule the next one.
            let delay = 1000/FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        } catch (err) {
            utils.printError(err);
        }
    };

    setTimeout(processVideo, 0);
}

function rgbaToGray(src, dst) {
    for (let i = 0, j = 0; i < src.length; i += 4, j += 1) {
      dst[j] = (src[i] * 77 + src[i + 1] * 150 + src[i + 2] * 29) >> 8;
    }
}

function drawResults(ctx, results, color, size) {
    for (let i = 0; i < results.size(); ++i) {
        let rect = results.get(i);
        ctx.lineWidth = 3;
        ctx.strokeStyle = color;
        ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
    }
}

utils.loadOpenCv(() => {
    utils.loadFileFromUrl('./haarcascade_frontalface_default.xml', (respnose) => {
        xml = respnose;
        startAndStop.removeAttribute('disabled');
    });
});
</script>
</body>
</html>
